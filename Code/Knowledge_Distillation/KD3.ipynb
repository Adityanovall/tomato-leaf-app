{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d0fee20-6895-4f98-9c02-8558afcba710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Teacher model loaded & frozen\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "TEACHER_PATH = \"baseline_mobilenetv3large_final.keras\"\n",
    "\n",
    "teacher = tf.keras.models.load_model(\n",
    "    TEACHER_PATH,\n",
    "    compile=False\n",
    ")\n",
    "teacher.trainable = False\n",
    "\n",
    "print(\"✅ Teacher model loaded & frozen\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2c0a5f1-9529-4336-9b8d-0f14fb92ba38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "✅ train_gen & val_gen siap untuk KD\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "DATASET_DIR = r\"C:\\Users\\adity\\Downloads\\dataset_split_final\"\n",
    "\n",
    "train_dir = os.path.join(DATASET_DIR, \"train\")\n",
    "val_dir   = os.path.join(DATASET_DIR, \"val\")\n",
    "\n",
    "# ⚠️ TANPA RESCALE (konsisten dengan training sebelumnya)\n",
    "datagen = ImageDataGenerator()\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"✅ train_gen & val_gen siap untuk KD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4003ca1-6384-4192-841d-654600e17937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Student model built\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = train_gen.num_classes\n",
    "\n",
    "base_student = tf.keras.applications.MobileNetV3Small(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "\n",
    "base_student.trainable = True\n",
    "\n",
    "x = base_student.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "outputs = tf.keras.layers.Dense(NUM_CLASSES)(x)  # logits\n",
    "\n",
    "student = tf.keras.Model(\n",
    "    inputs=base_student.input,\n",
    "    outputs=outputs\n",
    ")\n",
    "\n",
    "print(\"✅ Student model built\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aede2b3-c0d8-4be4-b0d4-4228a99727b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distiller(tf.keras.Model):\n",
    "    def __init__(self, student, teacher, temperature=4.0, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.student = student\n",
    "        self.teacher = teacher\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.student_loss_fn = tf.keras.losses.CategoricalCrossentropy(\n",
    "            from_logits=True\n",
    "        )\n",
    "        self.distill_loss_fn = tf.keras.losses.KLDivergence()\n",
    "        self.metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "    def compile(self, optimizer):\n",
    "        super().compile()\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y_true = data\n",
    "\n",
    "        teacher_logits = self.teacher(x, training=False)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            student_logits = self.student(x, training=True)\n",
    "\n",
    "            # Hard loss\n",
    "            student_loss = self.student_loss_fn(y_true, student_logits)\n",
    "\n",
    "            # Soft loss\n",
    "            soft_teacher = tf.nn.softmax(\n",
    "                teacher_logits / self.temperature, axis=1\n",
    "            )\n",
    "            soft_student = tf.nn.softmax(\n",
    "                student_logits / self.temperature, axis=1\n",
    "            )\n",
    "\n",
    "            distill_loss = self.distill_loss_fn(\n",
    "                soft_teacher, soft_student\n",
    "            ) * (self.temperature ** 2)\n",
    "\n",
    "            total_loss = (\n",
    "                self.alpha * student_loss +\n",
    "                (1 - self.alpha) * distill_loss\n",
    "            )\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.student.trainable_variables)\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads, self.student.trainable_variables)\n",
    "        )\n",
    "\n",
    "        self.metric.update_state(y_true, tf.nn.softmax(student_logits))\n",
    "\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"student_loss\": student_loss,\n",
    "            \"distill_loss\": distill_loss,\n",
    "            \"accuracy\": self.metric.result()\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        logits = self.student(x, training=False)\n",
    "        loss = self.student_loss_fn(y, logits)\n",
    "        self.metric.update_state(y, tf.nn.softmax(logits))\n",
    "        return {\"loss\": loss, \"accuracy\": self.metric.result()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bb61bb4-8d4a-40ad-b7a8-b94e003392ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Distiller compiled\n"
     ]
    }
   ],
   "source": [
    "distiller = Distiller(\n",
    "    student=student,\n",
    "    teacher=teacher,\n",
    "    temperature=3.0,\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "distiller.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    ")\n",
    "\n",
    "print(\"✅ Distiller compiled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a72e2fab-ca39-484d-97d9-cdac5450fcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 436ms/step - accuracy: 0.6130 - distill_loss: 0.5413 - loss: 0.7734 - student_loss: 0.8729 - val_accuracy: 0.6150 - val_loss: 1.1055\n",
      "Epoch 2/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 435ms/step - accuracy: 0.9487 - distill_loss: 0.6223 - loss: 0.4779 - student_loss: 0.4160 - val_accuracy: 0.8850 - val_loss: 0.5038\n",
      "Epoch 3/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 430ms/step - accuracy: 0.9734 - distill_loss: 0.6037 - loss: 0.4215 - student_loss: 0.3435 - val_accuracy: 0.9450 - val_loss: 0.4327\n",
      "Epoch 4/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 432ms/step - accuracy: 0.9829 - distill_loss: 0.5899 - loss: 0.3898 - student_loss: 0.3040 - val_accuracy: 0.9770 - val_loss: 0.3489\n",
      "Epoch 5/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 428ms/step - accuracy: 0.9904 - distill_loss: 0.5771 - loss: 0.3716 - student_loss: 0.2836 - val_accuracy: 0.9800 - val_loss: 0.4097\n",
      "Epoch 6/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 434ms/step - accuracy: 0.9948 - distill_loss: 0.5701 - loss: 0.3560 - student_loss: 0.2642 - val_accuracy: 0.9830 - val_loss: 0.3617\n",
      "Epoch 7/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 436ms/step - accuracy: 0.9924 - distill_loss: 0.5623 - loss: 0.3484 - student_loss: 0.2568 - val_accuracy: 0.9870 - val_loss: 0.3409\n",
      "Epoch 8/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 430ms/step - accuracy: 0.9951 - distill_loss: 0.5565 - loss: 0.3386 - student_loss: 0.2453 - val_accuracy: 0.9850 - val_loss: 0.3849\n",
      "Epoch 9/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 442ms/step - accuracy: 0.9976 - distill_loss: 0.5517 - loss: 0.3312 - student_loss: 0.2366 - val_accuracy: 0.9860 - val_loss: 0.3410\n",
      "Epoch 10/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 436ms/step - accuracy: 0.9970 - distill_loss: 0.5476 - loss: 0.3271 - student_loss: 0.2326 - val_accuracy: 0.9860 - val_loss: 0.3374\n",
      "Epoch 11/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 438ms/step - accuracy: 0.9967 - distill_loss: 0.5451 - loss: 0.3222 - student_loss: 0.2267 - val_accuracy: 0.9870 - val_loss: 0.2633\n",
      "Epoch 12/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 433ms/step - accuracy: 0.9976 - distill_loss: 0.5411 - loss: 0.3210 - student_loss: 0.2267 - val_accuracy: 0.9860 - val_loss: 0.2866\n",
      "Epoch 13/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 434ms/step - accuracy: 0.9985 - distill_loss: 0.5390 - loss: 0.3179 - student_loss: 0.2231 - val_accuracy: 0.9880 - val_loss: 0.2684\n",
      "Epoch 14/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 434ms/step - accuracy: 0.9991 - distill_loss: 0.5370 - loss: 0.3143 - student_loss: 0.2189 - val_accuracy: 0.9860 - val_loss: 0.2885\n",
      "Epoch 15/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 436ms/step - accuracy: 0.9989 - distill_loss: 0.5370 - loss: 0.3143 - student_loss: 0.2188 - val_accuracy: 0.9860 - val_loss: 0.2498\n",
      "Epoch 16/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 433ms/step - accuracy: 0.9986 - distill_loss: 0.5343 - loss: 0.3117 - student_loss: 0.2163 - val_accuracy: 0.9870 - val_loss: 0.2834\n",
      "Epoch 17/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 436ms/step - accuracy: 0.9991 - distill_loss: 0.5339 - loss: 0.3102 - student_loss: 0.2144 - val_accuracy: 0.9840 - val_loss: 0.2169\n",
      "Epoch 18/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 442ms/step - accuracy: 0.9994 - distill_loss: 0.5327 - loss: 0.3080 - student_loss: 0.2117 - val_accuracy: 0.9900 - val_loss: 0.2490\n",
      "Epoch 19/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 438ms/step - accuracy: 0.9992 - distill_loss: 0.5311 - loss: 0.3082 - student_loss: 0.2126 - val_accuracy: 0.9900 - val_loss: 0.2379\n",
      "Epoch 20/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 434ms/step - accuracy: 0.9992 - distill_loss: 0.5309 - loss: 0.3063 - student_loss: 0.2101 - val_accuracy: 0.9890 - val_loss: 0.2623\n",
      "Epoch 21/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 438ms/step - accuracy: 0.9993 - distill_loss: 0.5302 - loss: 0.3060 - student_loss: 0.2100 - val_accuracy: 0.9890 - val_loss: 0.2901\n",
      "Epoch 22/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 435ms/step - accuracy: 0.9991 - distill_loss: 0.5298 - loss: 0.3050 - student_loss: 0.2086 - val_accuracy: 0.9790 - val_loss: 0.2375\n"
     ]
    }
   ],
   "source": [
    "history_kd = distiller.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=30,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bfdc63b-5588-4d16-a5f5-185f79aaedbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ KD Student model saved\n"
     ]
    }
   ],
   "source": [
    "student.save(\"student_kd3_mobilenetv3small.keras\")\n",
    "print(\"✅ KD Student model saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7cf99f-8b3e-4b93-bbe8-1eaead547a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
