{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c31da5dd-d47c-4ff4-aad4-e64367c5a373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Teacher model loaded & frozen\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "TEACHER_PATH = \"baseline_mobilenetv3large_final.keras\"\n",
    "\n",
    "teacher = tf.keras.models.load_model(\n",
    "    TEACHER_PATH,\n",
    "    compile=False\n",
    ")\n",
    "teacher.trainable = False\n",
    "\n",
    "print(\"✅ Teacher model loaded & frozen\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbdc4fbb-12b9-450a-8eef-7b1f4045dea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "✅ train_gen & val_gen siap untuk KD\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "DATASET_DIR = r\"C:\\Users\\adity\\Downloads\\dataset_split_final\"\n",
    "\n",
    "train_dir = os.path.join(DATASET_DIR, \"train\")\n",
    "val_dir   = os.path.join(DATASET_DIR, \"val\")\n",
    "\n",
    "# ⚠️ TANPA RESCALE (konsisten dengan training sebelumnya)\n",
    "datagen = ImageDataGenerator()\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"✅ train_gen & val_gen siap untuk KD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddc05501-ce87-4290-925d-bdffbf42fd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Student model built\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = train_gen.num_classes\n",
    "\n",
    "base_student = tf.keras.applications.MobileNetV3Small(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "\n",
    "base_student.trainable = True\n",
    "\n",
    "x = base_student.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "outputs = tf.keras.layers.Dense(NUM_CLASSES)(x)  # logits\n",
    "\n",
    "student = tf.keras.Model(\n",
    "    inputs=base_student.input,\n",
    "    outputs=outputs\n",
    ")\n",
    "\n",
    "print(\"✅ Student model built\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b572fe0-9464-43b9-9450-408cb884edef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distiller(tf.keras.Model):\n",
    "    def __init__(self, student, teacher, temperature=4.0, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.student = student\n",
    "        self.teacher = teacher\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.student_loss_fn = tf.keras.losses.CategoricalCrossentropy(\n",
    "            from_logits=True\n",
    "        )\n",
    "        self.distill_loss_fn = tf.keras.losses.KLDivergence()\n",
    "        self.metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "    def compile(self, optimizer):\n",
    "        super().compile()\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y_true = data\n",
    "\n",
    "        teacher_logits = self.teacher(x, training=False)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            student_logits = self.student(x, training=True)\n",
    "\n",
    "            # Hard loss\n",
    "            student_loss = self.student_loss_fn(y_true, student_logits)\n",
    "\n",
    "            # Soft loss\n",
    "            soft_teacher = tf.nn.softmax(\n",
    "                teacher_logits / self.temperature, axis=1\n",
    "            )\n",
    "            soft_student = tf.nn.softmax(\n",
    "                student_logits / self.temperature, axis=1\n",
    "            )\n",
    "\n",
    "            distill_loss = self.distill_loss_fn(\n",
    "                soft_teacher, soft_student\n",
    "            ) * (self.temperature ** 2)\n",
    "\n",
    "            total_loss = (\n",
    "                self.alpha * student_loss +\n",
    "                (1 - self.alpha) * distill_loss\n",
    "            )\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.student.trainable_variables)\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads, self.student.trainable_variables)\n",
    "        )\n",
    "\n",
    "        self.metric.update_state(y_true, tf.nn.softmax(student_logits))\n",
    "\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"student_loss\": student_loss,\n",
    "            \"distill_loss\": distill_loss,\n",
    "            \"accuracy\": self.metric.result()\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        logits = self.student(x, training=False)\n",
    "        loss = self.student_loss_fn(y, logits)\n",
    "        self.metric.update_state(y, tf.nn.softmax(logits))\n",
    "        return {\"loss\": loss, \"accuracy\": self.metric.result()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3cc560e-b189-4e9d-a56f-a829ce73d985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Distiller compiled\n"
     ]
    }
   ],
   "source": [
    "distiller = Distiller(\n",
    "    student=student,\n",
    "    teacher=teacher,\n",
    "    temperature=2.0,\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "distiller.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    ")\n",
    "\n",
    "print(\"✅ Distiller compiled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ae7271a-f1a8-4f9e-9b2e-18c8b9c61c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 461ms/step - accuracy: 0.5808 - distill_loss: 0.5319 - loss: 0.8136 - student_loss: 0.9343 - val_accuracy: 0.3020 - val_loss: 1.9316\n",
      "Epoch 2/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 451ms/step - accuracy: 0.9440 - distill_loss: 0.6425 - loss: 0.5174 - student_loss: 0.4638 - val_accuracy: 0.7640 - val_loss: 0.8295\n",
      "Epoch 3/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 438ms/step - accuracy: 0.9731 - distill_loss: 0.6272 - loss: 0.4550 - student_loss: 0.3812 - val_accuracy: 0.9260 - val_loss: 0.5543\n",
      "Epoch 4/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 434ms/step - accuracy: 0.9861 - distill_loss: 0.6155 - loss: 0.4209 - student_loss: 0.3375 - val_accuracy: 0.9540 - val_loss: 0.4481\n",
      "Epoch 5/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 429ms/step - accuracy: 0.9863 - distill_loss: 0.6061 - loss: 0.4062 - student_loss: 0.3205 - val_accuracy: 0.9700 - val_loss: 0.3953\n",
      "Epoch 6/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 429ms/step - accuracy: 0.9927 - distill_loss: 0.5993 - loss: 0.3892 - student_loss: 0.2991 - val_accuracy: 0.9810 - val_loss: 0.4230\n",
      "Epoch 7/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 430ms/step - accuracy: 0.9957 - distill_loss: 0.5929 - loss: 0.3790 - student_loss: 0.2873 - val_accuracy: 0.9810 - val_loss: 0.3926\n",
      "Epoch 8/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 434ms/step - accuracy: 0.9970 - distill_loss: 0.5862 - loss: 0.3700 - student_loss: 0.2773 - val_accuracy: 0.9900 - val_loss: 0.4539\n",
      "Epoch 9/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 436ms/step - accuracy: 0.9979 - distill_loss: 0.5822 - loss: 0.3626 - student_loss: 0.2684 - val_accuracy: 0.9880 - val_loss: 0.5060\n",
      "Epoch 10/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 433ms/step - accuracy: 0.9975 - distill_loss: 0.5778 - loss: 0.3577 - student_loss: 0.2634 - val_accuracy: 0.9890 - val_loss: 0.3639\n",
      "Epoch 11/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 433ms/step - accuracy: 0.9968 - distill_loss: 0.5755 - loss: 0.3542 - student_loss: 0.2594 - val_accuracy: 0.9890 - val_loss: 0.4343\n",
      "Epoch 12/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 436ms/step - accuracy: 0.9976 - distill_loss: 0.5719 - loss: 0.3512 - student_loss: 0.2566 - val_accuracy: 0.9880 - val_loss: 0.4700\n",
      "Epoch 13/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 435ms/step - accuracy: 0.9985 - distill_loss: 0.5694 - loss: 0.3486 - student_loss: 0.2540 - val_accuracy: 0.9860 - val_loss: 0.3219\n",
      "Epoch 14/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 432ms/step - accuracy: 0.9988 - distill_loss: 0.5678 - loss: 0.3444 - student_loss: 0.2487 - val_accuracy: 0.9910 - val_loss: 0.3311\n",
      "Epoch 15/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 436ms/step - accuracy: 0.9979 - distill_loss: 0.5669 - loss: 0.3435 - student_loss: 0.2478 - val_accuracy: 0.9910 - val_loss: 0.4396\n",
      "Epoch 16/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 441ms/step - accuracy: 0.9997 - distill_loss: 0.5640 - loss: 0.3402 - student_loss: 0.2443 - val_accuracy: 0.9890 - val_loss: 0.4071\n",
      "Epoch 17/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 436ms/step - accuracy: 0.9995 - distill_loss: 0.5632 - loss: 0.3405 - student_loss: 0.2451 - val_accuracy: 0.9870 - val_loss: 0.3724\n",
      "Epoch 18/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 444ms/step - accuracy: 0.9982 - distill_loss: 0.5632 - loss: 0.3404 - student_loss: 0.2449 - val_accuracy: 0.9890 - val_loss: 0.3813\n"
     ]
    }
   ],
   "source": [
    "history_kd = distiller.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=30,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ea027d8-43ca-4638-94b5-511a8c83d25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ KD Student model saved\n"
     ]
    }
   ],
   "source": [
    "student.save(\"student_kd2_mobilenetv3small.keras\")\n",
    "print(\"✅ KD Student model saved\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
