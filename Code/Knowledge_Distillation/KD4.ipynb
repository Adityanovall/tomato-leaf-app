{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "901f6589-84bc-4117-8bcb-46e8facd5285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Teacher model loaded & frozen\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "TEACHER_PATH = \"baseline_mobilenetv3large_final.keras\"\n",
    "\n",
    "teacher = tf.keras.models.load_model(\n",
    "    TEACHER_PATH,\n",
    "    compile=False\n",
    ")\n",
    "teacher.trainable = False\n",
    "\n",
    "print(\"✅ Teacher model loaded & frozen\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "896d3d2c-33a7-4d38-a4da-9b7d3a08f660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "✅ train_gen & val_gen siap untuk KD\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "DATASET_DIR = r\"C:\\Users\\adity\\Downloads\\dataset_split_final\"\n",
    "\n",
    "train_dir = os.path.join(DATASET_DIR, \"train\")\n",
    "val_dir   = os.path.join(DATASET_DIR, \"val\")\n",
    "\n",
    "# ⚠️ TANPA RESCALE (konsisten dengan training sebelumnya)\n",
    "datagen = ImageDataGenerator()\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"✅ train_gen & val_gen siap untuk KD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68229d04-c940-4c12-9f72-1f42b2c17590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Student model built\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = train_gen.num_classes\n",
    "\n",
    "base_student = tf.keras.applications.MobileNetV3Small(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "\n",
    "base_student.trainable = True\n",
    "\n",
    "x = base_student.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "outputs = tf.keras.layers.Dense(NUM_CLASSES)(x)  # logits\n",
    "\n",
    "student = tf.keras.Model(\n",
    "    inputs=base_student.input,\n",
    "    outputs=outputs\n",
    ")\n",
    "\n",
    "print(\"✅ Student model built\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96ae5c23-d86c-4287-8b2a-544ba5205047",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distiller(tf.keras.Model):\n",
    "    def __init__(self, student, teacher, temperature=4.0, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.student = student\n",
    "        self.teacher = teacher\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.student_loss_fn = tf.keras.losses.CategoricalCrossentropy(\n",
    "            from_logits=True\n",
    "        )\n",
    "        self.distill_loss_fn = tf.keras.losses.KLDivergence()\n",
    "        self.metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "    def compile(self, optimizer):\n",
    "        super().compile()\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y_true = data\n",
    "\n",
    "        teacher_logits = self.teacher(x, training=False)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            student_logits = self.student(x, training=True)\n",
    "\n",
    "            # Hard loss\n",
    "            student_loss = self.student_loss_fn(y_true, student_logits)\n",
    "\n",
    "            # Soft loss\n",
    "            soft_teacher = tf.nn.softmax(\n",
    "                teacher_logits / self.temperature, axis=1\n",
    "            )\n",
    "            soft_student = tf.nn.softmax(\n",
    "                student_logits / self.temperature, axis=1\n",
    "            )\n",
    "\n",
    "            distill_loss = self.distill_loss_fn(\n",
    "                soft_teacher, soft_student\n",
    "            ) * (self.temperature ** 2)\n",
    "\n",
    "            total_loss = (\n",
    "                self.alpha * student_loss +\n",
    "                (1 - self.alpha) * distill_loss\n",
    "            )\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.student.trainable_variables)\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads, self.student.trainable_variables)\n",
    "        )\n",
    "\n",
    "        self.metric.update_state(y_true, tf.nn.softmax(student_logits))\n",
    "\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"student_loss\": student_loss,\n",
    "            \"distill_loss\": distill_loss,\n",
    "            \"accuracy\": self.metric.result()\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        logits = self.student(x, training=False)\n",
    "        loss = self.student_loss_fn(y, logits)\n",
    "        self.metric.update_state(y, tf.nn.softmax(logits))\n",
    "        return {\"loss\": loss, \"accuracy\": self.metric.result()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0fbe694-ee87-4f2f-8d8d-258eca6d3b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Distiller compiled\n"
     ]
    }
   ],
   "source": [
    "distiller = Distiller(\n",
    "    student=student,\n",
    "    teacher=teacher,\n",
    "    temperature=3.0,\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "distiller.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    ")\n",
    "\n",
    "print(\"✅ Distiller compiled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "676b3771-b20d-4193-9820-0b155a75b424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 450ms/step - accuracy: 0.6237 - distill_loss: 0.5362 - loss: 0.7587 - student_loss: 0.8541 - val_accuracy: 0.5380 - val_loss: 1.5213\n",
      "Epoch 2/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 436ms/step - accuracy: 0.9440 - distill_loss: 0.6173 - loss: 0.4765 - student_loss: 0.4162 - val_accuracy: 0.9120 - val_loss: 0.7592\n",
      "Epoch 3/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 440ms/step - accuracy: 0.9700 - distill_loss: 0.5996 - loss: 0.4185 - student_loss: 0.3409 - val_accuracy: 0.9530 - val_loss: 0.5050\n",
      "Epoch 4/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 435ms/step - accuracy: 0.9846 - distill_loss: 0.5863 - loss: 0.3865 - student_loss: 0.3008 - val_accuracy: 0.9710 - val_loss: 0.4845\n",
      "Epoch 5/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 446ms/step - accuracy: 0.9911 - distill_loss: 0.5753 - loss: 0.3673 - student_loss: 0.2782 - val_accuracy: 0.9660 - val_loss: 0.4360\n",
      "Epoch 6/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 438ms/step - accuracy: 0.9927 - distill_loss: 0.5666 - loss: 0.3534 - student_loss: 0.2620 - val_accuracy: 0.9780 - val_loss: 0.3729\n",
      "Epoch 7/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 436ms/step - accuracy: 0.9939 - distill_loss: 0.5592 - loss: 0.3460 - student_loss: 0.2546 - val_accuracy: 0.9810 - val_loss: 0.3301\n",
      "Epoch 8/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 438ms/step - accuracy: 0.9968 - distill_loss: 0.5537 - loss: 0.3352 - student_loss: 0.2415 - val_accuracy: 0.9860 - val_loss: 0.3831\n",
      "Epoch 9/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 441ms/step - accuracy: 0.9969 - distill_loss: 0.5504 - loss: 0.3290 - student_loss: 0.2341 - val_accuracy: 0.9880 - val_loss: 0.3870\n",
      "Epoch 10/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 437ms/step - accuracy: 0.9971 - distill_loss: 0.5460 - loss: 0.3259 - student_loss: 0.2316 - val_accuracy: 0.9820 - val_loss: 0.3176\n",
      "Epoch 11/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 437ms/step - accuracy: 0.9979 - distill_loss: 0.5431 - loss: 0.3204 - student_loss: 0.2249 - val_accuracy: 0.9770 - val_loss: 0.2766\n",
      "Epoch 12/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 433ms/step - accuracy: 0.9986 - distill_loss: 0.5419 - loss: 0.3182 - student_loss: 0.2223 - val_accuracy: 0.9900 - val_loss: 0.3262\n",
      "Epoch 13/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 444ms/step - accuracy: 0.9983 - distill_loss: 0.5389 - loss: 0.3167 - student_loss: 0.2215 - val_accuracy: 0.9850 - val_loss: 0.3357\n",
      "Epoch 14/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 453ms/step - accuracy: 0.9993 - distill_loss: 0.5376 - loss: 0.3146 - student_loss: 0.2190 - val_accuracy: 0.9840 - val_loss: 0.3682\n",
      "Epoch 15/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 444ms/step - accuracy: 0.9985 - distill_loss: 0.5357 - loss: 0.3114 - student_loss: 0.2153 - val_accuracy: 0.9780 - val_loss: 0.3110\n",
      "Epoch 16/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 446ms/step - accuracy: 0.9978 - distill_loss: 0.5351 - loss: 0.3123 - student_loss: 0.2168 - val_accuracy: 0.9880 - val_loss: 0.2661\n",
      "Epoch 17/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 438ms/step - accuracy: 0.9995 - distill_loss: 0.5336 - loss: 0.3087 - student_loss: 0.2123 - val_accuracy: 0.9840 - val_loss: 0.3560\n",
      "Epoch 18/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 439ms/step - accuracy: 0.9982 - distill_loss: 0.5334 - loss: 0.3109 - student_loss: 0.2155 - val_accuracy: 0.9890 - val_loss: 0.3167\n",
      "Epoch 19/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 495ms/step - accuracy: 0.9994 - distill_loss: 0.5316 - loss: 0.3073 - student_loss: 0.2112 - val_accuracy: 0.9940 - val_loss: 0.3020\n",
      "Epoch 20/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 531ms/step - accuracy: 0.9995 - distill_loss: 0.5311 - loss: 0.3067 - student_loss: 0.2105 - val_accuracy: 0.9860 - val_loss: 0.2816\n",
      "Epoch 21/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 541ms/step - accuracy: 0.9983 - distill_loss: 0.5305 - loss: 0.3070 - student_loss: 0.2112 - val_accuracy: 0.9920 - val_loss: 0.2636\n",
      "Epoch 22/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 526ms/step - accuracy: 0.9986 - distill_loss: 0.5295 - loss: 0.3075 - student_loss: 0.2124 - val_accuracy: 0.9730 - val_loss: 0.2682\n",
      "Epoch 23/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 525ms/step - accuracy: 0.9994 - distill_loss: 0.5302 - loss: 0.3060 - student_loss: 0.2099 - val_accuracy: 0.9860 - val_loss: 0.2568\n",
      "Epoch 24/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 514ms/step - accuracy: 0.9991 - distill_loss: 0.5291 - loss: 0.3042 - student_loss: 0.2079 - val_accuracy: 0.9880 - val_loss: 0.2882\n",
      "Epoch 25/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 515ms/step - accuracy: 0.9997 - distill_loss: 0.5287 - loss: 0.3036 - student_loss: 0.2071 - val_accuracy: 0.9950 - val_loss: 0.2991\n",
      "Epoch 26/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 512ms/step - accuracy: 0.9991 - distill_loss: 0.5281 - loss: 0.3050 - student_loss: 0.2095 - val_accuracy: 0.9890 - val_loss: 0.3027\n",
      "Epoch 27/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 521ms/step - accuracy: 0.9996 - distill_loss: 0.5279 - loss: 0.3034 - student_loss: 0.2071 - val_accuracy: 0.9930 - val_loss: 0.2737\n",
      "Epoch 28/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 535ms/step - accuracy: 0.9993 - distill_loss: 0.5271 - loss: 0.3053 - student_loss: 0.2102 - val_accuracy: 0.9810 - val_loss: 0.2535\n",
      "Epoch 29/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 518ms/step - accuracy: 0.9988 - distill_loss: 0.5281 - loss: 0.3030 - student_loss: 0.2066 - val_accuracy: 0.9900 - val_loss: 0.3169\n",
      "Epoch 30/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 515ms/step - accuracy: 0.9993 - distill_loss: 0.5272 - loss: 0.3039 - student_loss: 0.2081 - val_accuracy: 0.9830 - val_loss: 0.2707\n"
     ]
    }
   ],
   "source": [
    "history_kd = distiller.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=30,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16039c76-e7b0-4e8d-bc3a-2d87c15debaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ KD Student model saved\n"
     ]
    }
   ],
   "source": [
    "student.save(\"student_kd4_mobilenetv3small.keras\")\n",
    "print(\"✅ KD Student model saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96e033f-eeb9-4bf8-a2e9-6452482e617e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
