{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fe797b0-e6e8-4b23-b6c0-cc24378a44e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Teacher model loaded & frozen\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "TEACHER_PATH = \"baseline_mobilenetv3large_final.keras\"\n",
    "\n",
    "teacher = tf.keras.models.load_model(\n",
    "    TEACHER_PATH,\n",
    "    compile=False\n",
    ")\n",
    "teacher.trainable = False\n",
    "\n",
    "print(\"✅ Teacher model loaded & frozen\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6226969-d661-4f47-a7bf-b69340dd3fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "✅ train_gen & val_gen siap untuk KD\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "DATASET_DIR = r\"C:\\Users\\adity\\Downloads\\dataset_split_final\"\n",
    "\n",
    "train_dir = os.path.join(DATASET_DIR, \"train\")\n",
    "val_dir   = os.path.join(DATASET_DIR, \"val\")\n",
    "\n",
    "# ⚠️ TANPA RESCALE (konsisten dengan training sebelumnya)\n",
    "datagen = ImageDataGenerator()\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"✅ train_gen & val_gen siap untuk KD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a2f001c-68c4-4163-acaf-09d2add5a26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Student model built\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = train_gen.num_classes\n",
    "\n",
    "base_student = tf.keras.applications.MobileNetV3Small(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "\n",
    "base_student.trainable = True\n",
    "\n",
    "x = base_student.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "outputs = tf.keras.layers.Dense(NUM_CLASSES)(x)  # logits\n",
    "\n",
    "student = tf.keras.Model(\n",
    "    inputs=base_student.input,\n",
    "    outputs=outputs\n",
    ")\n",
    "\n",
    "print(\"✅ Student model built\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "576bf127-9391-4aea-89c4-77650f5a4f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distiller(tf.keras.Model):\n",
    "    def __init__(self, student, teacher, temperature=4.0, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.student = student\n",
    "        self.teacher = teacher\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.student_loss_fn = tf.keras.losses.CategoricalCrossentropy(\n",
    "            from_logits=True\n",
    "        )\n",
    "        self.distill_loss_fn = tf.keras.losses.KLDivergence()\n",
    "        self.metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "    def compile(self, optimizer):\n",
    "        super().compile()\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y_true = data\n",
    "\n",
    "        teacher_logits = self.teacher(x, training=False)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            student_logits = self.student(x, training=True)\n",
    "\n",
    "            # Hard loss\n",
    "            student_loss = self.student_loss_fn(y_true, student_logits)\n",
    "\n",
    "            # Soft loss\n",
    "            soft_teacher = tf.nn.softmax(\n",
    "                teacher_logits / self.temperature, axis=1\n",
    "            )\n",
    "            soft_student = tf.nn.softmax(\n",
    "                student_logits / self.temperature, axis=1\n",
    "            )\n",
    "\n",
    "            distill_loss = self.distill_loss_fn(\n",
    "                soft_teacher, soft_student\n",
    "            ) * (self.temperature ** 2)\n",
    "\n",
    "            total_loss = (\n",
    "                self.alpha * student_loss +\n",
    "                (1 - self.alpha) * distill_loss\n",
    "            )\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.student.trainable_variables)\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads, self.student.trainable_variables)\n",
    "        )\n",
    "\n",
    "        self.metric.update_state(y_true, tf.nn.softmax(student_logits))\n",
    "\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"student_loss\": student_loss,\n",
    "            \"distill_loss\": distill_loss,\n",
    "            \"accuracy\": self.metric.result()\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        logits = self.student(x, training=False)\n",
    "        loss = self.student_loss_fn(y, logits)\n",
    "        self.metric.update_state(y, tf.nn.softmax(logits))\n",
    "        return {\"loss\": loss, \"accuracy\": self.metric.result()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "798860eb-ffa6-4ddf-b1df-452b3a21f195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Distiller compiled\n"
     ]
    }
   ],
   "source": [
    "distiller = Distiller(\n",
    "    student=student,\n",
    "    teacher=teacher,\n",
    "    temperature=1.0,\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "distiller.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    ")\n",
    "\n",
    "print(\"✅ Distiller compiled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c43a7aa5-0331-488a-8617-fef3f9f3f796",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 478ms/step - accuracy: 0.5818 - distill_loss: 0.5755 - loss: 0.8246 - student_loss: 0.9313 - val_accuracy: 0.4990 - val_loss: 1.5657\n",
      "Epoch 2/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 450ms/step - accuracy: 0.9412 - distill_loss: 0.7201 - loss: 0.5455 - student_loss: 0.4707 - val_accuracy: 0.7900 - val_loss: 1.0195\n",
      "Epoch 3/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 441ms/step - accuracy: 0.9770 - distill_loss: 0.7098 - loss: 0.4913 - student_loss: 0.3976 - val_accuracy: 0.9430 - val_loss: 0.9450\n",
      "Epoch 4/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 436ms/step - accuracy: 0.9829 - distill_loss: 0.7019 - loss: 0.4618 - student_loss: 0.3588 - val_accuracy: 0.9660 - val_loss: 0.8283\n",
      "Epoch 5/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 434ms/step - accuracy: 0.9887 - distill_loss: 0.6915 - loss: 0.4444 - student_loss: 0.3385 - val_accuracy: 0.9620 - val_loss: 0.8621\n",
      "Epoch 6/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 440ms/step - accuracy: 0.9917 - distill_loss: 0.6882 - loss: 0.4317 - student_loss: 0.3218 - val_accuracy: 0.9760 - val_loss: 0.8137\n",
      "Epoch 7/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 435ms/step - accuracy: 0.9949 - distill_loss: 0.6823 - loss: 0.4247 - student_loss: 0.3144 - val_accuracy: 0.9800 - val_loss: 0.6901\n",
      "Epoch 8/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 436ms/step - accuracy: 0.9953 - distill_loss: 0.6770 - loss: 0.4160 - student_loss: 0.3042 - val_accuracy: 0.9820 - val_loss: 0.4790\n",
      "Epoch 9/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 431ms/step - accuracy: 0.9972 - distill_loss: 0.6757 - loss: 0.4104 - student_loss: 0.2966 - val_accuracy: 0.9870 - val_loss: 0.5372\n",
      "Epoch 10/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 438ms/step - accuracy: 0.9967 - distill_loss: 0.6709 - loss: 0.4083 - student_loss: 0.2957 - val_accuracy: 0.9870 - val_loss: 0.5866\n",
      "Epoch 11/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 434ms/step - accuracy: 0.9979 - distill_loss: 0.6673 - loss: 0.4022 - student_loss: 0.2886 - val_accuracy: 0.9860 - val_loss: 0.5553\n",
      "Epoch 12/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 435ms/step - accuracy: 0.9978 - distill_loss: 0.6662 - loss: 0.3990 - student_loss: 0.2844 - val_accuracy: 0.9880 - val_loss: 0.4781\n",
      "Epoch 13/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 434ms/step - accuracy: 0.9982 - distill_loss: 0.6635 - loss: 0.3966 - student_loss: 0.2823 - val_accuracy: 0.9880 - val_loss: 0.4120\n",
      "Epoch 14/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 443ms/step - accuracy: 0.9991 - distill_loss: 0.6627 - loss: 0.3942 - student_loss: 0.2792 - val_accuracy: 0.9830 - val_loss: 0.5644\n",
      "Epoch 15/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 441ms/step - accuracy: 0.9978 - distill_loss: 0.6602 - loss: 0.3941 - student_loss: 0.2800 - val_accuracy: 0.9890 - val_loss: 0.5038\n",
      "Epoch 16/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 444ms/step - accuracy: 0.9994 - distill_loss: 0.6607 - loss: 0.3895 - student_loss: 0.2732 - val_accuracy: 0.9880 - val_loss: 0.4746\n",
      "Epoch 17/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 437ms/step - accuracy: 0.9987 - distill_loss: 0.6570 - loss: 0.3897 - student_loss: 0.2752 - val_accuracy: 0.9860 - val_loss: 0.4583\n",
      "Epoch 18/30\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 435ms/step - accuracy: 0.9987 - distill_loss: 0.6579 - loss: 0.3902 - student_loss: 0.2754 - val_accuracy: 0.9860 - val_loss: 0.4751\n"
     ]
    }
   ],
   "source": [
    "history_kd = distiller.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=30,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53f2f868-3c0c-41f4-afbb-e5acabc365d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ KD Student model saved\n"
     ]
    }
   ],
   "source": [
    "student.save(\"student_kd_mobilenetv3small.keras\")\n",
    "print(\"✅ KD Student model saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf815dd-af3a-42db-aaeb-e53ac33902b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
